{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "以下のいずれかの環境でGPUあり、なしを設定し,PytorchからGPUが見えるか確認してください.\n",
    "- Google Colaboratory \n",
    "- Kaggle Kernel\n",
    "\n",
    "資料にはあまり情報を載せていないので検索してみてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習2: 以下の微分をpytorchで計算してみてください.\n",
    "__注意__: 入力は適当に決めてください.\n",
    "- $e^{x}$\n",
    "- $\\cos x$\n",
    "- $\\sin x$\n",
    "- $x^2$\n",
    "- $\\frac{e^{ax}}{e^{ax} + e^{bx}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.tensor(3., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(20.0855),)\n",
      "(tensor(-0.1411),)\n",
      "(tensor(-0.9900),)\n",
      "(tensor(6.),)\n",
      "(tensor(0.0452),)\n"
     ]
    }
   ],
   "source": [
    "print(torch.autograd.grad(torch.exp(X1), X1))\n",
    "print(torch.autograd.grad(torch.cos(X1), X1))\n",
    "print(torch.autograd.grad(torch.sin(X1), X1))\n",
    "print(torch.autograd.grad(X1 ** 2, X1))\n",
    "print(torch.autograd.grad(torch.exp(3 *X1)/(torch.exp(3*X1) + torch.exp(2*X1)), X1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習3: 以下の微分をpytorchで計算してみてください.\n",
    "以降では,\n",
    "$y = \\frac{e^{ax}}{e^{ax} + e^{bx}}$として$z$を$x$で微分してください.\n",
    "__注意__: 入力は適当に決めてください.\n",
    "- $z = sin(y)$\n",
    "- $\\cos y$\n",
    "- $\\sin y$\n",
    "- $y^2$\n",
    "- $\\frac{e^{ay}}{e^{ay} + e^{by}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.exp(3 *X1)/(torch.exp(3*X1) + torch.exp(2*X1))\n",
    "z1 = torch.exp(y)\n",
    "z2 = torch.cos(y)\n",
    "z3 = torch.sin(y)\n",
    "z4 = y * y\n",
    "z5 = torch.exp(3 *y)/(torch.exp(3*y) + torch.exp(2*y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.1171),)\n",
      "(tensor(-0.0368),)\n",
      "(tensor(0.0262),)\n",
      "(tensor(0.0861),)\n",
      "(tensor(0.0091),)\n"
     ]
    }
   ],
   "source": [
    "print(torch.autograd.grad(z1, X1,retain_graph=True))\n",
    "print(torch.autograd.grad(z2, X1,retain_graph=True))\n",
    "print(torch.autograd.grad(z3, X1,retain_graph=True))\n",
    "print(torch.autograd.grad(z4, X1,retain_graph=True))\n",
    "print(torch.autograd.grad(z5, X1,retain_graph=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100個のランダムな3次元のfloat型Tensorを持つDatasetクラスを自作してください\n",
    "- DatasetクラスというのはPytorchの torch.utils.data.Datasaetクラスを継承したクラスのことです。\n",
    "- 条件\n",
    "  - lenが100\n",
    "  - 同じindexを指定した時に同じ値が帰ってくる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 考えること\n",
    "- 今回必要な操作は何だ?\n",
    "- Datasetクラスを継承するにはどうすればいいか?\n",
    "- 必要な操作のためには`__init__`で共通の情報として何を定義すればよいか考える\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 今回必要な操作\n",
    "作りたいインスタンスを`dataset`とします。\n",
    "- len(dataset) = 100\n",
    "- dataset[i]が3次元のfloat型Tensor(iは0から99)\n",
    "- dataset[i]は何度実行しても同じ値になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3次元\n",
    "- 3次元が指すもの(今回はどちらでもOK)\n",
    "    - `[a, b, c]`\n",
    "    - `[\n",
    "  [\n",
    "  [a]\n",
    "  ]\n",
    "  ]\n",
    "  `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __init__で必要な情報\n",
    "- dataとして100×3次元のtensorを作れたらよい\n",
    "```python\n",
    "__init__(self):\n",
    "  self.data = 100×3次元のtesor\n",
    "\n",
    "__getitem__(self, index):\n",
    "    return self.data[index]\n",
    " \n",
    "__len__(self):\n",
    "    return self.data.shape[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 考え方として\n",
    "以下のようなものもOK\n",
    "- dataを外から作る\n",
    "```python\n",
    "__init__(self, data): # dataは100×3次元のtensor\n",
    "    self.data = data \n",
    "```\n",
    "\n",
    "- `random seed`をindexに応じて指定し,`return rand(3)`\n",
    "のもなくはない.\n",
    "\n",
    "- `__len__`は100と決まっているので、  \n",
    "  return 100でもいい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythonのパッケージのパス\n",
    "- ディレクトリが`torch/utils/data`の場合\n",
    "  `torch.utils.data`が該当する場所を指す\n",
    "- torch.utils.data.dataset.DatasetにDatasetクラスは定義されている\n",
    "- `torch/utils/data/__init__.py`で `from .dataset import Dataset`とされているため,data.Datasetでdata.dataset.Datasetを呼び出すことができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.randn(100,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 4, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.dataset.Dataset == torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Dataset at 0x12618b4e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tensor([0.0361, 0.1921, 0.8778])\n",
      "tensor([0.0361, 0.1921, 0.8778])\n"
     ]
    }
   ],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataset = torch.rand(100,3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 100\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index]\n",
    "\n",
    "rd = RandomDataset()\n",
    "print(len(rd))\n",
    "print(rd[0])\n",
    "print(rd[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "入力4次元,出力3次元の活性化関数がReLUの三層のDNNをnn.Sequential, nn.Module二通りの使い方で実装しなさい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4754,  0.7621, -0.1280], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(4, 3)\n",
    "        self.l2 = nn.Linear(3, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.l1(x)\n",
    "        o = F.relu(o)\n",
    "        return self.l2(o)\n",
    "        \n",
    "net = Net()\n",
    "net(torch.tensor([1., 2., 3., 4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5681, -0.3191,  0.5662], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4,3), nn.ReLU(), nn.Linear(3, 3))\n",
    "net(torch.tensor([1., 2., 3., 4.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "以下のソースコードはそのままでは動かない.何箇所か修正し,活性化関数ReLUの3層のnnの計算を実行せよ.\n",
    "```python\n",
    "class Net(Module):\n",
    "    def __init__(self, netwoerks):\n",
    "        self.networks = networks\n",
    "\n",
    "    def forward(self, x):\n",
    "        for net in self.networks:\n",
    "            net(x)\n",
    "net = Net([nn.Linear(3,5), nn.Linear(5, 4)])\n",
    "net(torch.tensor([1, 2, 3]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答は自分が作ってください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "以下のソースコードではそのままでは動かない.何箇所が修正し,(1,2,3,4)に対する出力が1になるようなSoftmax回帰を実装せよ.\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        l1 = nn.Linear(4, 3)\n",
    "        return l1(x)\n",
    "    \n",
    "net, x, y = Net(), torch.tensor([[1,2,3,4]]), torch.tensor([1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters())\n",
    "loss = net(x)\n",
    "[loss.backward() for _ in range(100)]    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答は自分が作ってください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "以下のソースコードではそのままでは動かない.何箇所が修正し,(1,2,3,4)に対する出力が1になるようなNNを実装せよ.\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.nn_list = [nn.Linear(4,4), nn.Linear(4, 3)]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in nn_list:\n",
    "            x = nn.ReLU()(l(x))\n",
    "        return x,\n",
    "net, x, y = Net(), torch.tensor([1,2,3,4], [2,3,10, 1]), torch.tensor([1, 2])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters())\n",
    "for i in range(100):\n",
    "    criterion(net(x), y).backward(); optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答は自分で作ってください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1946, 0.1541, 0.0000, 0.7322], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, networks):\n",
    "        super().__init__()\n",
    "        self.networks = networks\n",
    "\n",
    "    def forward(self, x):\n",
    "        for net in self.networks:\n",
    "            x = F.relu(net(x))\n",
    "        return x\n",
    "net = Net(nn.ModuleList([nn.Linear(3,5), nn.Linear(5, 4)]))\n",
    "net(torch.tensor([1., 2., 3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(4, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "    \n",
    "net, x, y = Net(), torch.tensor([[1,2,3,4]]).float(), torch.tensor([1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "for _ in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(net(x), y)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3692,  4.4583, -0.8471]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.nn_list = nn.ModuleList([nn.Linear(4,4), nn.ReLU(), nn.Linear(4, 1)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.nn_list:\n",
    "            x = l(x)\n",
    "        return x\n",
    "net, x, y = Net(), torch.tensor([[1,2,3,4], [2,3,10, 1]]).float(), torch.tensor([[1], [2]]).float()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    criterion(net(x), y).backward();\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0031],\n",
       "        [1.9981]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
