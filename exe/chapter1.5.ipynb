{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "以下のいずれかの環境でGPUあり、なしを設定し,PytorchからGPUが見えるか確認してください.\n",
    "- Google Colaboratory \n",
    "- Kaggle Kernel\n",
    "\n",
    "資料にはあまり情報を載せていないので検索してみてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習2: 以下の微分をpytorchで計算してみてください.\n",
    "__注意__: 入力は適当に決めてください.\n",
    "- $e^{x}$\n",
    "- $\\cos x$\n",
    "- $\\sin x$\n",
    "- $x^2$\n",
    "- $\\frac{e^{ax}}{e^{ax} + e^{bx}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = torch.tensor(3., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(20.0855),)\n",
      "(tensor(-0.1411),)\n",
      "(tensor(-0.9900),)\n",
      "(tensor(6.),)\n",
      "(tensor(0.0452),)\n"
     ]
    }
   ],
   "source": [
    "print(torch.autograd.grad(torch.exp(X1), X1))\n",
    "print(torch.autograd.grad(torch.cos(X1), X1))\n",
    "print(torch.autograd.grad(torch.sin(X1), X1))\n",
    "print(torch.autograd.grad(X1 ** 2, X1))\n",
    "print(torch.autograd.grad(torch.exp(3 *X1)/(torch.exp(3*X1) + torch.exp(2*X1)), X1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習3: 以下の微分をpytorchで計算してみてください.\n",
    "以降では,\n",
    "$y = \\frac{e^{ax}}{e^{ax} + e^{bx}}$として$z$を$x$で微分してください.\n",
    "__注意__: 入力は適当に決めてください.\n",
    "- $z = sin(y)$\n",
    "- $\\cos y$\n",
    "- $\\sin y$\n",
    "- $y^2$\n",
    "- $\\frac{e^{ay}}{e^{ay} + e^{by}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.exp(3 *X1)/(torch.exp(3*X1) + torch.exp(2*X1))\n",
    "z1 = torch.exp(y)\n",
    "z2 = torch.cos(y)\n",
    "z3 = torch.sin(y)\n",
    "z4 = y * y\n",
    "z5 = torch.exp(3 *y)/(torch.exp(3*y) + torch.exp(2*y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.1171),)\n",
      "(tensor(-0.0368),)\n",
      "(tensor(0.0262),)\n",
      "(tensor(0.0861),)\n",
      "(tensor(0.0091),)\n"
     ]
    }
   ],
   "source": [
    "print(torch.autograd.grad(z1, X1,retain_graph=True))\n",
    "print(torch.autograd.grad(z2, X1,retain_graph=True))\n",
    "print(torch.autograd.grad(z3, X1,retain_graph=True))\n",
    "print(torch.autograd.grad(z4, X1,retain_graph=True))\n",
    "print(torch.autograd.grad(z5, X1,retain_graph=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100個のランダムな3次元のfloat型Tensorを持つDatasetクラスを自作してください\n",
    "- 条件\n",
    "  - lenが100\n",
    "  - 同じindexを指定した時に同じ値が帰ってく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tensor([0.1564, 0.8517, 0.5447])\n",
      "tensor([0.1564, 0.8517, 0.5447])\n"
     ]
    }
   ],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataset = torch.rand(100,3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 100\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index]\n",
    "\n",
    "rd = RandomDataset()\n",
    "print(len(rd))\n",
    "print(rd[0])\n",
    "print(rd[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "入力4次元,出力3次元の活性化関数がReLUの三層のDNNをnn.Sequential, nn.Module二通りの使い方で実装しなさい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4754,  0.7621, -0.1280], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(4, 3)\n",
    "        self.l2 = nn.Linear(3, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o = self.l1(x)\n",
    "        o = F.relu(o)\n",
    "        return self.l2(o)\n",
    "        \n",
    "net = Net()\n",
    "net(torch.tensor([1., 2., 3., 4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5681, -0.3191,  0.5662], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4,3), nn.ReLU(), nn.Linear(3, 3))\n",
    "net(torch.tensor([1., 2., 3., 4.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "以下のソースコードはそのままでは動かない.何箇所か修正し,活性化関数ReLUの3層のnnの計算を実行せよ.\n",
    "```python\n",
    "class Net(Module):\n",
    "    def __init__(self, netwoerks):\n",
    "        self.networks = networks\n",
    "\n",
    "    def forward(self, x):\n",
    "        for net in self.networks:\n",
    "            net(x)\n",
    "net = Net([nn.Linear(3,5), nn.Linear(5, 4)])\n",
    "net(torch.tensor([1, 2, 3]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答は自分が作ってください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "以下のソースコードではそのままでは動かない.何箇所が修正し,(1,2,3,4)に対する出力が1になるようなSoftmax回帰を実装せよ.\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        l1 = nn.Linear(4, 3)\n",
    "        return l1(x)\n",
    "    \n",
    "net, x, y = Net(), torch.tensor([[1,2,3,4]]), torch.tensor([1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters())\n",
    "loss = net(x)\n",
    "[loss.backward() for _ in range(100)]    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答は自分が作ってください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "以下のソースコードではそのままでは動かない.何箇所が修正し,(1,2,3,4)に対する出力が1になるようなNNを実装せよ.\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.nn_list = [nn.Linear(4,4), nn.Linear(4, 3)]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in nn_list:\n",
    "            x = nn.ReLU()(l(x))\n",
    "        return x,\n",
    "net, x, y = Net(), torch.tensor([1,2,3,4], [2,3,10, 1]), torch.tensor([1, 2])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters())\n",
    "for i in range(100):\n",
    "    criterion(net(x), y).backward(); optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答は自分で作ってください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
