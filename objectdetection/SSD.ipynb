{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# XMLをファイルやテキストから読み込んだり、加工したり、保存したりするためのライブラリ\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import cv2\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datapath_list(root_dir):\n",
    "    \n",
    "    root_dir = Path(root_dir)\n",
    "    img_dir = root_dir / \"JPEGImages\"\n",
    "    ann_dir = root_dir / \"Annotations\"\n",
    "    \n",
    "    train_id_name_txt = root_dir / \"ImageSets\" / \"Main\" / \"train.txt\"\n",
    "    valid_id_name_txt = root_dir / \"ImageSets\" / \"Main\" / \"val.txt\"\n",
    "    \n",
    "    train_img_list = []\n",
    "    train_ann_list = []\n",
    "    \n",
    "    for line in open(train_id_name_txt):\n",
    "        file_id = line.strip()\n",
    "        train_img_list.append(img_dir / f\"{file_id}.jpg\")\n",
    "        train_ann_list.append(ann_dir / f\"{file_id}.xml\")\n",
    "    \n",
    "    valid_img_list = []\n",
    "    valid_ann_list = []\n",
    "    \n",
    "    for line in open(valid_id_name_txt):\n",
    "        file_id = line.strip()\n",
    "        valid_img_list.append(img_dir / f\"{file_id}.jpg\")\n",
    "        valid_ann_list.append(ann_dir / f\"{file_id}.xml\")\n",
    "\n",
    "    return train_img_list, train_ann_list, valid_img_list, valid_ann_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ファイル確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルパスのリストを作成\n",
    "root_dir  = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = get_datapath_list(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xml2ListConverter():\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "        \n",
    "    def __call__(self, xml_path, widht, height):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        [[xmin, ymin, xmax, ymax, label]...]\n",
    "        \"\"\"\n",
    "        \n",
    "        anno_list = []\n",
    "        \n",
    "        xml = ET.parse(xml_path).getroot()\n",
    "        \n",
    "        # 難しいもの削除\n",
    "        for obj in xml.iter(\"object\"):\n",
    "            \n",
    "            if int(obj.find('difficult').text) == 1:\n",
    "                continue\n",
    "                \n",
    "            bnd_box = []\n",
    "            \n",
    "            name = obj.find('name').text.lower().strip()\n",
    "            bbox = obj.find('bndbox')  \n",
    "            \n",
    "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "            \n",
    "            for pt in pts:\n",
    "                #VOCの原点移動\n",
    "                size = int(bbox.find(pt).text) - 1\n",
    "                size = size/ height if pt.find(\"y\") > -1 else size / width\n",
    "                \n",
    "                bnd_box.append(size)\n",
    "            \n",
    "            label_idx = self.classes.index(name)\n",
    "            \n",
    "            bnd_box.append(label_idx)\n",
    "            \n",
    "            anno_list.append(bnd_box)\n",
    "   \n",
    "        return np.array(anno_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.888     , 0.67466667, 0.998     , 0.89066667, 6.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# クラス定義\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "xml_converter = Xml2ListConverter(voc_classes)\n",
    "\n",
    "ind = 10\n",
    "image_file_path = val_img_list[ind]\n",
    "# Pathlibば読めない\n",
    "img = cv2.imread(str(image_file_path))  \n",
    "height, width, channels = img.shape  \n",
    "\n",
    "# アノテーションをリストで表示\n",
    "xml_converter(val_anno_list[ind], width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理と準備 \n",
    "- Datasetクラス\n",
    "- Dataloader\n",
    "- transfomerを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline():\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __call__(self, img, boxes=None, labels=None):\n",
    "        for transform in self.transformes:\n",
    "            # 必ず引数が3つ必要\n",
    "            # 予測時はboxes, labels共にNoneなので、それを前提に作成数するひつつ用あり\n",
    "            img, boxes, labels = transforme(img, boxex, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変形を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self, input_size, color_mean):\n",
    "        self.preprocess - {\n",
    "            \"train\": Pipeline([\n",
    "                \n",
    "            ]),\n",
    "            \"val\": Pipeline([\n",
    "                \n",
    "            ])\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def __call__(self, img, mode, boxes, labels):\n",
    "        \n",
    "        return self.preprocess[mode](img, boxes=None, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
