{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装\n",
    "- クロスエントロピー\n",
    "- 仮説"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 損失の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4375)\n"
     ]
    }
   ],
   "source": [
    "preds = torch.tensor([[0.2, 0.8]]) # 二値分類\n",
    "labels = torch.tensor([1]) # 正解ラベル\n",
    "\n",
    "loss = criterion(preds, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "- 3×3のモデル\n",
    "- クロスエントロピー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(np.arange(12).reshape(4, 3)).float()\n",
    "Y = torch.tensor([1, 2, 0, 1])\n",
    "model = nn.Linear(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0542, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(model(X), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorchで\n",
    "- 勾配降下\n",
    "- ニュートン法\n",
    "\n",
    "で ルート2を求める\n",
    "\n",
    "- 勾配降下の場合\n",
    "  - $f(x) = x^3 - 6x$で計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(x):\n",
    "    return x ** 3 -  6 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0.01], requires_grad=True)\n",
    "y = F(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loop tensor([0.6100], grad_fn=<SubBackward0>)\n",
      "1 loop tensor([1.0984], grad_fn=<SubBackward0>)\n",
      "2 loop tensor([1.3364], grad_fn=<SubBackward0>)\n",
      "3 loop tensor([1.4006], grad_fn=<SubBackward0>)\n",
      "4 loop tensor([1.4121], grad_fn=<SubBackward0>)\n",
      "5 loop tensor([1.4139], grad_fn=<SubBackward0>)\n",
      "6 loop tensor([1.4142], grad_fn=<SubBackward0>)\n",
      "7 loop tensor([1.4142], grad_fn=<SubBackward0>)\n",
      "8 loop tensor([1.4142], grad_fn=<SubBackward0>)\n",
      "9 loop tensor([1.4142], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    y = F(x)\n",
    "    z = torch.autograd.grad(y, x)\n",
    "    x = x - learning_rate * z[0]\n",
    "    print(i, \"loop\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ニュートン法の場合\n",
    "  - $f(x) = x^2 - 2$で計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(x):\n",
    "    return x ** 2 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0.1], requires_grad=True)\n",
    "y = G(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9900], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lootp tensor([10.0500], requires_grad=True)\n",
      "1 lootp tensor([5.1245], requires_grad=True)\n",
      "2 lootp tensor([2.7574], requires_grad=True)\n",
      "3 lootp tensor([1.7414], requires_grad=True)\n",
      "4 lootp tensor([1.4449], requires_grad=True)\n",
      "5 lootp tensor([1.4145], requires_grad=True)\n",
      "6 lootp tensor([1.4142], requires_grad=True)\n",
      "7 lootp tensor([1.4142], requires_grad=True)\n",
      "8 lootp tensor([1.4142], requires_grad=True)\n",
      "9 lootp tensor([1.4142], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    y = G(x)\n",
    "    y.backward()\n",
    "    # backwardで値を入れる時はdataに代入\n",
    "    # xに代入すると,backwardの対象でなくなる\n",
    "    x.data = x.data - y/ x.grad\n",
    "    print(i, \"lootp\", x)\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorchで実装するべきこと\n",
    "0. データ準備\n",
    "1. モデル設計\n",
    "    - パラメータ/仮説\n",
    "    - 損失関数\n",
    "2. 学習\n",
    "    - 勾配を計算\n",
    "    - 勾配降下法によってパラメータ更新\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris[\"feature_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasetとは\n",
    "- データの集まり\n",
    "- サイズ\n",
    "- 特定のインデクスでデータを取れる\n",
    "- 前処理を上から加えられる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasetの抽象クラス\n",
    "- 実際こういう定義のよう\n",
    "  - `__len__` (すらない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __add__(self, other):\n",
    "        # ConcatDatasetの定義が必要だが省略\n",
    "        return ConcatDataset([self, other])\n",
    "    # No `def __len__(self)` default?\n",
    "    # See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\n",
    "    # in pytorch/torch/utils/data/sampler.py\n",
    "    # https://github.com/pytorch/pytorch/blob/master/torch/utils/data/sampler.py#L24\n",
    "    # lenを決めるデフォルトのルールが決めづらい(元のデータのlenではだめな場合に何で決める?)\n",
    "    # lenが`raise NotImplementedError()`になることを使ってる処理が存在する\n",
    "    # 一旦はlenをデフォルトにいれないことに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        data = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if not self.transform is None:\n",
    "            data, label = self.transform(data, label)\n",
    "        \n",
    "        return data, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_transform(data, label):\n",
    "    return torch.tensor(data).float(), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(iris.data, iris.target, test_size=0.2)\n",
    "\n",
    "iris_train_dataset = IrisDataset(X_train, y_train, iris_transform)\n",
    "iris_valid_dataset = IrisDataset(X_valid, y_valid, iris_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None, multiprocessing_context=None)\n",
    "```\n",
    "\n",
    "- dataset: datasetならOK(`__len__`, `__add__`)が必要\n",
    "- `batch_size`: 一つのデータ数\n",
    "- `shuffle, sampler, batch_sampler`: データの選び方\n",
    "- `num_workers`: プロセスの数\n",
    "- `collate_fn`: `DataLoeader`での後処理\n",
    "- `pin_memory`: `CUDA`用の設定、GPUのメモリでページングしない設定\n",
    "- `drop_last`: 最後のデータを使うか\n",
    "- `timeout, worker_init_fn, multiprocessing_context`: 今回は省略(最初は使わないはず)\n",
    "\n",
    "基本的にはデータを連結してiteratorとしてくれるもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([5.1000, 3.7000, 1.5000, 0.4000]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "for x in iris_train_dataset:\n",
    "    print(x)\n",
    "    break\n",
    "    # batchにはなっていない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size  = 24 # ミニバッチのデータの数\n",
    "iris_train_dataloader = torch.utils.data.DataLoader(iris_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "iris_valid_dataloader = torch.utils.data.DataLoader(iris_valid_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自作datasetを使わない実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(iris.data, iris.target, test_size=0.2)\n",
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train)\n",
    "X_valid = torch.tensor(X_valid).float()\n",
    "y_valid = torch.tensor(y_valid)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "valid_dataset = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                   batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                   batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax回帰の実装\n",
    "- irisに対し,softmax回帰で実装する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(4, 3)\n",
    "\n",
    "batch_size  = 120 # ミニバッチのデータの数\n",
    "max_epoch = 100 #\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 損失の定義\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) #(確率的)勾配降下法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[ 1.4900,  2.3964, -3.5998, -1.9053],\n",
       "           [ 0.8754,  0.2335, -0.4544, -1.2168],\n",
       "           [-1.7652, -2.8074,  3.5882,  3.6563]], requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([ 0.2773,  0.8967, -1.8454], requires_grad=True)],\n",
       "  'lr': 0.01,\n",
       "  'momentum': 0,\n",
       "  'dampening': 0,\n",
       "  'weight_decay': 0,\n",
       "  'nesterov': False}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for data, target in iris_train_dataloader: # 入力と正解\n",
    "    optimizer.zero_grad() # Weightの初期化\n",
    "    output = model(data) # 仮説で値代入\n",
    "    loss = criterion(output, target) # 損失\n",
    "    loss.backward() # 微分の計算\n",
    "    optimizer.step() # パラメータの更新\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "pred = output.argmax(axis=1).cpu().detach()\n",
    "ans = target.cpu()\n",
    "print(\"accuracy\", accuracy_score(ans, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.01,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'params': [5331858128, 5331857840]}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.4900,  2.3964, -3.5997, -1.9053],\n",
      "        [ 0.8753,  0.2335, -0.4544, -1.2167],\n",
      "        [-1.7652, -2.8074,  3.5881,  3.6562]], requires_grad=True)\n",
      "tensor([[-0.0010, -0.0028,  0.0037,  0.0018],\n",
      "        [ 0.1136,  0.0479,  0.0916,  0.0365],\n",
      "        [-0.1126, -0.0452, -0.0953, -0.0383]])\n"
     ]
    }
   ],
   "source": [
    "print(model.weight)\n",
    "print(model.weight.grad)\n",
    "old_weight = model.weight.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for data, target in train_loader: # 入力と正解\n",
    "    optimizer.zero_grad() # Weightの初期化\n",
    "    output = model(data) # 仮説で値代入\n",
    "    loss = criterion(output, target) # 損失\n",
    "    loss.backward() # 微分の計算\n",
    "    optimizer.step() # パラメータの更新\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.4900,  2.3964, -3.5998, -1.9053],\n",
      "        [ 0.8754,  0.2335, -0.4544, -1.2168],\n",
      "        [-1.7652, -2.8074,  3.5882,  3.6563]], requires_grad=True)\n",
      "tensor([[-0.0013, -0.0033,  0.0048,  0.0022],\n",
      "        [-0.0027, -0.0005, -0.0008,  0.0020],\n",
      "        [ 0.0040,  0.0039, -0.0040, -0.0042]])\n"
     ]
    }
   ],
   "source": [
    "# after\n",
    "print(model.weight)\n",
    "print(model.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4900,  2.3964, -3.5997, -1.9053],\n",
       "        [ 0.8753,  0.2335, -0.4544, -1.2167],\n",
       "        [-1.7652, -2.8074,  3.5881,  3.6562]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4900,  2.3964, -3.5997, -1.9053],\n",
       "        [ 0.8753,  0.2335, -0.4544, -1.2167],\n",
       "        [-1.7652, -2.8074,  3.5881,  3.6562]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight + optimizer.state_dict()['param_groups'][0][\"lr\"] * model.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの勾配が消える\n",
    "model.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(data) # 仮説で値代入\n",
    "loss = criterion(output, target) # 損失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward() # 微分の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.4398,  1.0046,  4.0171,  1.5467],\n",
       "        [-3.3215, -1.5426, -2.4041, -0.7414],\n",
       "        [-0.1183,  0.5379, -1.6130, -0.8053]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0349,  0.2804,  0.2858,  0.1865],\n",
       "        [-0.4398,  0.2456,  0.1448,  0.4426],\n",
       "        [ 0.4975,  0.1777, -0.3319, -0.3443]], requires_grad=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() # パラメータの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0339,  0.2603,  0.2054,  0.1555],\n",
       "        [-0.3733,  0.2764,  0.1929,  0.4575],\n",
       "        [ 0.4999,  0.1670, -0.2996, -0.3282]], requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracyの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 二次元配列\n",
    "# データの個数 ×出力の次元\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argmaxを計算する\n",
    "pred = output.argmax(axis=1)\n",
    "# pytorchっぽい情報を落とす\n",
    "# detachは計算グラフの情報を落とす\n",
    "pred = pred.cpu().detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracyの計算は以下を使えばよい\n",
    "- `sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)[source]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ans, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score([0, 1], [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score([0, 0], [0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習・評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader): # 入力と正解\n",
    "         optimizer.zero_grad() # Weightの初期化\n",
    "         output = model(data) # 仮説で値代入\n",
    "         loss = criterion(output, target) # 損失\n",
    "         loss.backward() # 微分の計算\n",
    "         optimizer.step() # パラメータの更新\n",
    "    if epoch % 10 == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        batch_idx, batch_idx * len(data), len(data_loader.dataset),\n",
    "        100. * batch_idx / len(data_loader), loss.item()))\n",
    "\n",
    "def valid_epoch(model, data_loader, epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader): # 入力と正解\n",
    "             optimizer.zero_grad() # Weightの初期化\n",
    "             output = model(data) # 仮説で値代入\n",
    "             output.dtype\n",
    "             loss = criterion(output, target) # 損失\n",
    "             # 本来は全体でロスを数えて荷重平均を取る,accuracyを計算する\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print('Test Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                batch_idx, batch_idx * len(data), len(data_loader.dataset),\n",
    "                100. * batch_idx / len(data_loader), loss.item()))\n",
    "                \n",
    "            pred = output.argmax(axis=1).cpu().detach().numpy()\n",
    "            ans = target.cpu().numpy()\n",
    "            print(\"accuracy\", accuracy_score(ans, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.452206\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.243792\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.016447\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.246481\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.013010\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.094238\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.305634\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.100549\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.004216\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.112896\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.012437\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.200404\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.099521\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.150629\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.213836\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.085671\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.179673\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.082730\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.051900\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.148467\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.072176\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.127928\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.181810\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.147349\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.067826\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.151746\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.030518\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.089524\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.035833\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.152129\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.317491\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.102730\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.011718\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.069975\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.009349\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.043755\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.017770\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.114231\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.025023\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.213211\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 1.576121\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.115380\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.063570\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.067576\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.061007\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.098134\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.013556\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.080904\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.003572\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.107237\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.422110\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.137073\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.003581\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.083433\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.031665\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.099843\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 1.772465\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.088324\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.014744\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.077350\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.019862\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.204072\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.019117\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.104759\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.005471\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.070114\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.052938\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.079154\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.044588\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.204804\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.063726\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.213940\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.429631\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.079538\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.019238\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.165940\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.006280\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.049377\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.069053\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.049810\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.007377\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.080344\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.036865\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.063543\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.064527\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.081374\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.004303\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.073725\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.011571\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.099263\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.013356\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.094603\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.126749\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.089306\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.036066\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.052492\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.005303\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.072794\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.036885\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.064094\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.109849\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.046121\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.041103\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.216288\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.020468\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.084240\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.010626\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.068370\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.192325\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.201014\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.005729\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.083958\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.001058\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.192927\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.072647\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.030235\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.225276\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.148669\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.039763\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.077952\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.011719\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.054956\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.034877\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.053560\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.040674\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.061885\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.006208\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.054179\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.004161\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.070088\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.075303\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.070539\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.406236\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.292879\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.012658\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.042890\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.032513\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.046286\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.026743\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.027191\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.019051\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.063528\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.068314\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.018336\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.007575\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.048768\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.040504\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.033108\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.083624\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.038960\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.025596\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.050031\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.134277\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.033453\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.004175\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.206046\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.683563\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.048769\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.030527\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.028881\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.234913\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.031704\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.708008\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.036566\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.809125\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.094685\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.007730\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.079891\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.038394\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.056941\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.208604\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.039925\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.032598\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.048919\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.000737\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.048416\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.163670\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.037750\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.000261\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.184950\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.007015\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.210619\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.001297\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.053653\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.082060\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.041253\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.008385\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.042589\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.667366\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.026805\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.017366\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.179207\n",
      "accuracy 0.8333333333333334\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.025669\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.045834\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.260739\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.068869\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.041791\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.043466\n",
      "accuracy 1.0\n",
      "Train Epoch: 17 [17/120 (94%)]\tLoss: 0.007552\n",
      "Test Epoch: 1 [6/30 (50%)]\tLoss: 0.041235\n",
      "accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch * 10):\n",
    "    train_epoch(model, iris_train_dataloader, epoch)\n",
    "    valid_epoch(model, iris_valid_dataloader, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全然関係ないもの"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaptivePooling\n",
    "毎回挙動が怪しくなるので確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.AdaptiveMaxPool2d(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.arange(24).reshape(1, 3, 8).astype(float))\n",
    "output = m(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 8])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19., 20., 21., 22., 23.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  3.5000,  6.0000],\n",
       "         [ 9.0000, 11.5000, 14.0000],\n",
       "         [17.0000, 19.5000, 22.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
