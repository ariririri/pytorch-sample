{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装\n",
    "- クロスエントロピー\n",
    "- 仮説"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 損失の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4375)\n"
     ]
    }
   ],
   "source": [
    "preds = torch.tensor([[0.2, 0.8]]) # 二値分類\n",
    "labels = torch.tensor([1]) # 正解ラベル\n",
    "\n",
    "loss = criterion(preds, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "- 3×3のモデル\n",
    "- クロスエントロピー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(np.arange(12).reshape(4, 3)).float()\n",
    "Y = torch.tensor([1, 2, 0, 1])\n",
    "model = nn.Linear(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3651, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(model(X), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorchで\n",
    "- 勾配降下\n",
    "- ニュートン法\n",
    "\n",
    "で ルート2を求める\n",
    "\n",
    "- 勾配降下の場合\n",
    "  - $f(x) = x^3 - 6x$で計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(x):\n",
    "    return x ** 3 -  6 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "y = F(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loop tensor([1.3000], grad_fn=<SubBackward0>)\n",
      "1 loop tensor([1.3930], grad_fn=<SubBackward0>)\n",
      "2 loop tensor([1.4109], grad_fn=<SubBackward0>)\n",
      "3 loop tensor([1.4137], grad_fn=<SubBackward0>)\n",
      "4 loop tensor([1.4141], grad_fn=<SubBackward0>)\n",
      "5 loop tensor([1.4142], grad_fn=<SubBackward0>)\n",
      "6 loop tensor([1.4142], grad_fn=<SubBackward0>)\n",
      "7 loop tensor([1.4142], grad_fn=<SubBackward0>)\n",
      "8 loop tensor([1.4142], grad_fn=<SubBackward0>)\n",
      "9 loop tensor([1.4142], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    y = F(x)\n",
    "    z = torch.autograd.grad(y, x)\n",
    "    x = x - learning_rate * z[0]\n",
    "    print(i, \"loop\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ニュートン法の場合\n",
    "  - $f(x) = x^3 - 6x$で計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(x):\n",
    "    return x ** 2 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "y = G(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lootp tensor([1.5000], requires_grad=True)\n",
      "1 lootp tensor([1.4167], requires_grad=True)\n",
      "2 lootp tensor([1.4142], requires_grad=True)\n",
      "3 lootp tensor([1.4142], requires_grad=True)\n",
      "4 lootp tensor([1.4142], requires_grad=True)\n",
      "5 lootp tensor([1.4142], requires_grad=True)\n",
      "6 lootp tensor([1.4142], requires_grad=True)\n",
      "7 lootp tensor([1.4142], requires_grad=True)\n",
      "8 lootp tensor([1.4142], requires_grad=True)\n",
      "9 lootp tensor([1.4142], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    y = G(x)\n",
    "    y.backward()\n",
    "    # backwardで値を入れる時はdataに代入\n",
    "    # xに代入すると,backwardの対象でなくなる\n",
    "    x.data = x.data - y/ x.grad\n",
    "    print(i, \"lootp\", x)\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax回帰の実装\n",
    "- irisに対し,softmax回帰で実装する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader):\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader): # 入力と正解\n",
    "         optimizer.zero_grad() # Weightの初期化\n",
    "         output = model(data) # 仮説で値代入\n",
    "         loss = criterion(output, target) # 損失\n",
    "         loss.backward() # 微分の計算\n",
    "         optimizer.step() # パラメータの更新\n",
    "         if batch_idx % 10 == 0:\n",
    "             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                 batch_idx, batch_idx * len(data), len(data_loader.dataset),\n",
    "                 100. * batch_idx / len(data_loader), loss.item()))\n",
    "\n",
    "def valid_epoch(model, data_loader):\n",
    "    model.train()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader): # 入力と正解\n",
    "             optimizer.zero_grad() # Weightの初期化\n",
    "             output = model(data) # 仮説で値代入\n",
    "             output.dtype\n",
    "             loss = criterion(output, target) # 損失\n",
    "             # 本来は全体でロスを数えて荷重平均を取る,accuracyを計算する\n",
    "\n",
    "             if batch_idx % 10 == 0:\n",
    "                 print('Test Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                     batch_idx, batch_idx * len(data), len(data_loader.dataset),\n",
    "                     100. * batch_idx / len(data_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(iris.data, iris.target, test_size=0.2)\n",
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train)\n",
    "X_valid = torch.tensor(X_valid).float()\n",
    "y_valid = torch.tensor(y_valid)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "valid_dataset = torch.utils.data.TensorDataset(X_valid, y_valid)\n",
    "\n",
    "model = nn.Linear(4, 3)\n",
    "\n",
    "batch_size  = 120 # ミニバッチのデータの数\n",
    "max_epoch = 100 #\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                   batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                   batch_size=batch_size, shuffle=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 損失の定義\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) #(確率的)勾配降下法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 2.696589\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 2.541242\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 2.541242\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 2.408026\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 2.408026\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 2.289122\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 2.289121\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 2.179420\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 2.179420\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 2.076118\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 2.076119\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.977985\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.977985\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.884750\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.884750\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.796715\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.796714\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.714491\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.714491\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.638829\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.638828\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.570448\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.570448\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.509903\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.509903\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.457444\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.457444\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.412937\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.412937\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.375854\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.375854\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.345344\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.345345\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.320365\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.320365\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.299823\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.299824\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.282703\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.282703\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.268132\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.268132\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.255413\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.255413\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.244018\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.244018\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.233561\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.233561\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.223769\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.223770\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.214456\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.214456\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.205492\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.205492\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.196794\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.196794\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.188304\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.188304\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.179985\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.179986\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.171813\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.171813\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.163771\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.163771\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.155848\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.155849\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.148038\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.148038\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.140335\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.140335\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.132735\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.132735\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.125237\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.125237\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.117838\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.117838\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.110537\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.110537\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.103333\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.103333\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.096224\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.096224\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.089210\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.089211\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.082289\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.082290\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.075462\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.075462\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.068726\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.068726\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.062080\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.062080\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.055524\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.055524\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.049057\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.049057\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.042678\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.042678\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.036386\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.036386\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.030180\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.030179\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.024058\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.024058\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.018021\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.018021\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.012067\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.012067\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.006194\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.006194\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 1.000403\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 1.000403\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.994692\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.994692\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.989059\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.989059\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.983504\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.983505\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.978027\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.978027\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.972625\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.972625\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.967298\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.967298\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.962045\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.962045\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.956864\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.956864\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.951755\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.951755\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.946717\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.946717\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.941749\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.941749\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.936849\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.936849\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.932018\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.932018\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.927253\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.927253\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.922554\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.922554\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.917919\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.917919\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.913348\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.913348\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.908840\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.908840\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.904394\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.904394\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.900009\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.900010\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.895684\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.895684\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.891419\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.891419\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.887210\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.887210\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.883060\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.883060\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.878965\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.878965\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.874926\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.874927\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.870942\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.870942\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.867011\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.867011\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.863133\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.863133\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.859308\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.859308\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.855533\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.855533\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.851808\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.851808\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.848133\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.848133\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.844507\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.844507\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.840929\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.840929\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.837398\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.837398\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.833913\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.833913\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.830473\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.830474\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.827079\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.827079\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.823729\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.823729\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.820422\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.820422\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.817157\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.817158\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.813935\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.813935\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.810754\n",
      "Train Epoch: 0 [0/120 (0%)]\tLoss: 0.810754\n",
      "Test Epoch: 0 [0/120 (0%)]\tLoss: 0.807613\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    train_epoch(model, train_loader)\n",
    "    valid_epoch(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 2, 2, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 1, 1, 2, 1, 1, 0,\n",
       "       1, 2, 2, 1, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
